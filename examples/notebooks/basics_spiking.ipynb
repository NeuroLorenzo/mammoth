{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec72291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/mammoth_conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script contains a simple example of how to use the Mammoth library.\n",
    "\n",
    "We will see:\n",
    "- How to load the necessary stuff to run a model on a particular dataset.\n",
    "- What arguments are available for the model and what are the required ones.\n",
    "- How to run a model.\n",
    "- How to save and load a model.\n",
    "\"\"\"\n",
    "from mammoth import train, load_runner, get_avail_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706a8624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] 28-Jan-26 12:42:00 - Error in model cgil\n",
      "[WARNING] 28-Jan-26 12:42:00 - Please install the CLIP package by running: pip install git+https://github.com/openai/CLIP.git\n",
      "[WARNING] 28-Jan-26 12:42:00 - Error in model clip\n",
      "[WARNING] 28-Jan-26 12:42:00 - Error in model dap\n",
      "[WARNING] 28-Jan-26 12:42:00 - No module named 'scipy'\n",
      "[WARNING] 28-Jan-26 12:42:00 - Error in model derpp-casper\n",
      "[WARNING] 28-Jan-26 12:42:00 - No module named 'xitorch'\n",
      "[WARNING] 28-Jan-26 12:42:00 - Error in model er-ace-aer-abs\n",
      "[WARNING] 28-Jan-26 12:42:00 - No module named 'sklearn'\n",
      "[WARNING] 28-Jan-26 12:42:00 - Error in model er-ace-casper\n",
      "[WARNING] 28-Jan-26 12:42:00 - Error in model first-stage-starprompt\n",
      "[WARNING] 28-Jan-26 12:42:00 - Please install the CLIP package by running: pip install git+https://github.com/openai/CLIP.git (requires also `huggingface-hub`)\n",
      "[WARNING] 28-Jan-26 12:42:00 - Error in model icarl-casper\n",
      "[WARNING] 28-Jan-26 12:42:00 - Error in model llava\n",
      "[WARNING] 28-Jan-26 12:42:00 - Please install the HuggingFace Transformers package by running: pip install transformers\n",
      "[WARNING] 28-Jan-26 12:42:00 - Error in model lws\n",
      "[WARNING] 28-Jan-26 12:42:00 - kmeans_pytorch not installed. Please run `pip install kmeans-pytorch`.\n",
      "[WARNING] 28-Jan-26 12:42:00 - Error in model puridiver\n",
      "[WARNING] 28-Jan-26 12:42:01 - Error in model second-stage-starprompt\n",
      "[WARNING] 28-Jan-26 12:42:01 - Error in model slca\n",
      "[WARNING] 28-Jan-26 12:42:01 - Error in model starprompt\n",
      "[WARNING] 28-Jan-26 12:42:01 - Error in model xder-rpc-casper\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Buffer size not found in the arguments. Please specify it with --buffer_size.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThe `get_avail_args` function returns a dictionary of available arguments for the model.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mThe arguments are divided into required and optional ones.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m \u001b[33;03m- The optional arguments are those that can be provided to customize the model's behavior (such as changing the batch_size or saving/loading a checkpoint).\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m required_args, optional_args = \u001b[43mget_avail_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mneuro-mnist\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msRNN\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRequired arguments:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m arg, info \u001b[38;5;129;01min\u001b[39;00m required_args.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/utente/Documents/Dottorato_Lorenzo/mammoth/utils/notebooks.py:87\u001b[39m, in \u001b[36mget_avail_args\u001b[39m\u001b[34m(dataset, model, args)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     85\u001b[39m     exp_str += [\u001b[33m\"\u001b[39m\u001b[33m--model\u001b[39m\u001b[33m\"\u001b[39m, model]\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m parser = \u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_parser_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m required_args, optional_args = {}, {}\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m parser._action_groups:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/utente/Documents/Dottorato_Lorenzo/mammoth/main.py:282\u001b[39m, in \u001b[36mparse_args\u001b[39m\u001b[34m(cmd, return_parser_only, verbose)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;66;03m# 3) load the configuration arguments for the dataset and model\u001b[39;00m\n\u001b[32m    280\u001b[39m add_configuration_args(parser, args)\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m config = \u001b[43mload_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m add_help(parser)\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# 4) add the remaining arguments\u001b[39;00m\n\u001b[32m    287\u001b[39m \n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# - get the chosen backbone. The CLI argument takes precedence over the configuration file.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/utente/Documents/Dottorato_Lorenzo/mammoth/main.py:160\u001b[39m, in \u001b[36mload_configs\u001b[39m\u001b[34m(parser, cmd)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_rehearsal:  \u001b[38;5;66;03m# get buffer size\u001b[39;00m\n\u001b[32m    159\u001b[39m     buffer_size = get_single_arg_value(parser, \u001b[33m'\u001b[39m\u001b[33mbuffer_size\u001b[39m\u001b[33m'\u001b[39m, cmd)\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m buffer_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mBuffer size not found in the arguments. Please specify it with --buffer_size.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    162\u001b[39m         buffer_size = \u001b[38;5;28mint\u001b[39m(buffer_size)  \u001b[38;5;66;03m# try convert to int, check if it is a valid number\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: Buffer size not found in the arguments. Please specify it with --buffer_size."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The `get_avail_args` function returns a dictionary of available arguments for the model.\n",
    "The arguments are divided into required and optional ones.\n",
    "\n",
    "- The required arguments are those that MUST be provided to run the model.\n",
    "- The optional arguments are those that can be provided to customize the model's behavior (such as changing the batch_size or saving/loading a checkpoint).\n",
    "\"\"\"\n",
    "\n",
    "required_args, optional_args = get_avail_args(dataset='neuro-mnist', model='sRNN')\n",
    "\n",
    "print(\"Required arguments:\")\n",
    "for arg, info in required_args.items():\n",
    "    print(f\"  {arg}: {info['description']}\")\n",
    "\n",
    "print(\"\\nOptional arguments:\")\n",
    "for arg, info in optional_args.items():\n",
    "    print(f\"  {arg}: {info['default']} - {info['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d73d1d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 15-Jan-26 17:02:29 - Trying to load default configuration for model sgd but no configuration file found in None.\n",
      "[INFO] 15-Jan-26 17:02:29 - Running in a notebook environment. Forcefully setting num_workers=0 to prevent issues with multiprocessing.\n",
      "[WARNING] 15-Jan-26 17:02:29 - No GPU available. Using CPU.\n",
      "[INFO] 15-Jan-26 17:02:29 - Using device cpu\n",
      "[INFO] 15-Jan-26 17:02:29 - `wandb_entity` and `wandb_project` not set. Disabling wandb.\n",
      "[INFO] 15-Jan-26 17:02:29 - Using backbone: resnet18\n",
      "[INFO] 15-Jan-26 17:02:30 - Using ResNet as backbone\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "To load the necessary stuff to run a model on a particular dataset, we can use the `load_runner` function.\n",
    "This function takes the model name, dataset name, and a dictionary of arguments as input.\n",
    "The dictionary of arguments can contain both required and optional arguments.\n",
    "\n",
    "The `load_runner` function returns the model and dataset to be used for training.\n",
    "The model and dataset are already set up with the provided arguments.\n",
    "\"\"\"\n",
    "\n",
    "model, dataset = load_runner('sgd','seq-cifar10',{'lr': 0.1, 'n_epochs': 1, 'batch_size': 32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa108461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 15-Jan-26 17:02:35 - Current working directory: /mnt/c/Users/utente/Documents/Dottorato_Lorenzo/mammoth.\n",
      "[INFO] 15-Jan-26 17:02:35 - Main process PID: 17492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 170M/170M [00:15<00:00, 11.2MB/s]\n",
      "/opt/mammoth_env/lib/python3.11/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 15-Jan-26 17:03:05 - Using 0 workers for the dataloader.\n",
      "[INFO] 15-Jan-26 17:03:05 - Using 0 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 1 - Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 313/313 [02:54<00:00,  1.80it/s, loss=0.356, lr=0.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP ITERATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:11<00:00,  5.48it/s, acc_task_1=89]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 15-Jan-26 17:06:10 - Accuracy for 1 task(s): \t [Class-IL]: 89.05 % \t [Task-IL]: 89.05 %\n",
      "[INFO] 15-Jan-26 17:06:10 - \tRaw accuracy values: Class-IL [89.05] | Task-IL [89.05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for 1 task(s): \t [Class-IL]: 89.05 % \t [Task-IL]: 89.05 %\n",
      "\tRaw accuracy values: Class-IL [89.05] | Task-IL [89.05]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 15-Jan-26 17:06:15 - Using 0 workers for the dataloader.\n",
      "[INFO] 15-Jan-26 17:06:15 - Using 0 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 2 - Epoch 1:  35%|███████████████████████████████                                                           | 108/313 [01:00<02:10,  1.58it/s, loss=0.611, lr=0.1]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We can now run the model on the dataset using the `train` function.\n",
    "\"\"\"\n",
    "train(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db845aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mammoth_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
